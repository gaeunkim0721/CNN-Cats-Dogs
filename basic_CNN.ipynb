{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoN03ksBOuq22VXOzlvl+i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaeunkim0721/CNN-Cats-Dogs/blob/main/basic_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1r6Cg_z4HaW"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4VelNoPbxaL",
        "outputId": "b9572374-66c4-4687-f9fa-2db57e077aa7"
      },
      "source": [
        "!unzip dogs_cats.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open dogs_cats.zip, dogs_cats.zip.zip or dogs_cats.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YjqpE9Z4HDw"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHOp5vGH4HGH"
      },
      "source": [
        "import keras\r\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi94k2lz4HIh"
      },
      "source": [
        "import glob\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "#from utils import log_progress\r\n",
        "\r\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YO_Gw0d4HNL"
      },
      "source": [
        "def log_progress(sequence, every=None, size=None, name='Items'):\r\n",
        "    from ipywidgets import IntProgress, HTML, VBox\r\n",
        "    from IPython.display import display\r\n",
        "\r\n",
        "    is_iterator = False\r\n",
        "    if size is None:\r\n",
        "        try:\r\n",
        "            size = len(sequence)\r\n",
        "        except TypeError:\r\n",
        "            is_iterator = True\r\n",
        "    if size is not None:\r\n",
        "        if every is None:\r\n",
        "            if size <= 200:\r\n",
        "                every = 1\r\n",
        "            else:\r\n",
        "                every = int(size / 200)     # every 0.5%\r\n",
        "    else:\r\n",
        "        assert every is not None, 'sequence is iterator, set every'\r\n",
        "\r\n",
        "    if is_iterator:\r\n",
        "        progress = IntProgress(min=0, max=1, value=1)\r\n",
        "        progress.bar_style = 'info'\r\n",
        "    else:\r\n",
        "        progress = IntProgress(min=0, max=size, value=0)\r\n",
        "    label = HTML()\r\n",
        "    box = VBox(children=[label, progress])\r\n",
        "    display(box)\r\n",
        "\r\n",
        "    index = 0\r\n",
        "    try:\r\n",
        "        for index, record in enumerate(sequence, 1):\r\n",
        "            if index == 1 or index % every == 0:\r\n",
        "                if is_iterator:\r\n",
        "                    label.value = '{name}: {index} / ?'.format(\r\n",
        "                        name=name,\r\n",
        "                        index=index\r\n",
        "                    )\r\n",
        "                else:\r\n",
        "                    progress.value = index\r\n",
        "                    label.value = u'{name}: {index} / {size}'.format(\r\n",
        "                        name=name,\r\n",
        "                        index=index,\r\n",
        "                        size=size\r\n",
        "                    )\r\n",
        "            yield record\r\n",
        "    except:\r\n",
        "        progress.bar_style = 'danger'\r\n",
        "        raise\r\n",
        "    else:\r\n",
        "        progress.bar_style = 'success'\r\n",
        "        progress.value = index\r\n",
        "        label.value = \"{name}: {index}\".format(\r\n",
        "            name=name,\r\n",
        "            index=str(index or '?')\r\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5--pQI6m4HSv"
      },
      "source": [
        "files = glob.glob('train/*')\r\n",
        "\r\n",
        "cat_files = [fn for fn in files if 'cat' in fn]\r\n",
        "dog_files = [fn for fn in files if 'dog' in fn]\r\n",
        "len(cat_files), len(dog_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5SKP3Lh4HVK"
      },
      "source": [
        "cat_train = np.random.choice(cat_files, size=1500, replace=False)\r\n",
        "dog_train = np.random.choice(dog_files, size=1500, replace=False)\r\n",
        "cat_files = list(set(cat_files) - set(cat_train))\r\n",
        "dog_files = list(set(dog_files) - set(dog_train))\r\n",
        "\r\n",
        "cat_val = np.random.choice(cat_files, size=500, replace=False)\r\n",
        "dog_val = np.random.choice(dog_files, size=500, replace=False)\r\n",
        "cat_files = list(set(cat_files) - set(cat_val))\r\n",
        "dog_files = list(set(dog_files) - set(dog_val))\r\n",
        "\r\n",
        "cat_test = np.random.choice(cat_files, size=500, replace=False)\r\n",
        "dog_test = np.random.choice(dog_files, size=500, replace=False)\r\n",
        "\r\n",
        "print('Cat datasets:', cat_train.shape, cat_val.shape, cat_test.shape)\r\n",
        "print('Dog datasets:', dog_train.shape, dog_val.shape, dog_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhNbL9NX4HX4"
      },
      "source": [
        "train_dir = 'training_data'\r\n",
        "val_dir = 'validation_data'\r\n",
        "test_dir = 'test_data'\r\n",
        "\r\n",
        "train_files = np.concatenate([cat_train, dog_train])\r\n",
        "validate_files = np.concatenate([cat_val, dog_val])\r\n",
        "test_files = np.concatenate([cat_test, dog_test])\r\n",
        "\r\n",
        "os.mkdir(train_dir) if not os.path.isdir(train_dir) else None\r\n",
        "os.mkdir(val_dir) if not os.path.isdir(val_dir) else None\r\n",
        "os.mkdir(test_dir) if not os.path.isdir(test_dir) else None\r\n",
        "\r\n",
        "for fn in log_progress(train_files, name='Training Images'):\r\n",
        "    shutil.copy(fn, train_dir)\r\n",
        "\r\n",
        "for fn in log_progress(validate_files, name='Validation Images'):\r\n",
        "    shutil.copy(fn, val_dir)\r\n",
        "    \r\n",
        "for fn in log_progress(test_files, name='Test Images'):\r\n",
        "    shutil.copy(fn, test_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RvGzLas4HfD"
      },
      "source": [
        "IMG_DIM = (150, 150)\r\n",
        "\r\n",
        "train_files = glob.glob('training_data/*')\r\n",
        "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\r\n",
        "train_imgs = np.array(train_imgs)\r\n",
        "train_labels = [fn.split('/')[1].split('.')[0].strip() for fn in train_files]\r\n",
        "\r\n",
        "validation_files = glob.glob('validation_data/*')\r\n",
        "validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]\r\n",
        "validation_imgs = np.array(validation_imgs)\r\n",
        "validation_labels = [fn.split('/')[1].split('.')[0].strip() for fn in validation_files]\r\n",
        "\r\n",
        "print('Train dataset shape:', train_imgs.shape, \r\n",
        "      '\\tValidation dataset shape:', validation_imgs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXvSCWnN4Hh_"
      },
      "source": [
        "train_imgs_scaled = train_imgs.astype('float32')\r\n",
        "validation_imgs_scaled  = validation_imgs.astype('float32')\r\n",
        "train_imgs_scaled /= 255\r\n",
        "validation_imgs_scaled /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFbk2IPF4Hkh"
      },
      "source": [
        "print(train_imgs[0].shape)\r\n",
        "array_to_img(train_imgs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hihVwXnS4Hm_"
      },
      "source": [
        "batch_size = 50\r\n",
        "num_classes = 2\r\n",
        "epochs = 150\r\n",
        "input_shape = (150, 150, 3)\r\n",
        "\r\n",
        "# encode text category labels\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "le = LabelEncoder()\r\n",
        "le.fit(train_labels)\r\n",
        "train_labels_enc = le.transform(train_labels)\r\n",
        "validation_labels_enc = le.transform(validation_labels)\r\n",
        "\r\n",
        "print(train_labels[1495:1505], train_labels_enc[1495:1505])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toxmawbb44U2"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2gyzId044eb"
      },
      "source": [
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\",  activation='relu', input_shape=input_shape),)\r\n",
        "model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\r\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\r\n",
        "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\r\n",
        "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "model.add(Conv2D(512, (3, 3), padding=\"same\", activation='relu'))\r\n",
        "model.add(Conv2D(512, (3, 3), padding=\"same\", activation='relu'))\r\n",
        "model.add(Conv2D(512, (3, 3), padding=\"same\", activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "model.add(Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
        "model.add(Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
        "model.add(Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(4096, activation='relu'))\r\n",
        "\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(4096, activation='relu'))\r\n",
        "\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer='rmsprop',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5m_VM5844hT"
      },
      "source": [
        "history = model.fit(x=train_imgs_scaled, y=train_labels_enc,\r\n",
        "                    validation_data=(validation_imgs_scaled, validation_labels_enc),\r\n",
        "                    batch_size=batch_size,\r\n",
        "                    epochs=epochs,\r\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa4sgueh44kO"
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\r\n",
        "t = f.suptitle('Basic CNN Performance', fontsize=12)\r\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\r\n",
        "\r\n",
        "epoch_list = list(range(1,101))\r\n",
        "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\r\n",
        "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\r\n",
        "ax1.set_xticks(np.arange(0, 101, 5))\r\n",
        "ax1.set_ylabel('Accuracy Value')\r\n",
        "ax1.set_xlabel('Epoch')\r\n",
        "ax1.set_title('Accuracy')\r\n",
        "l1 = ax1.legend(loc=\"best\")\r\n",
        "\r\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\r\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\r\n",
        "ax2.set_xticks(np.arange(0, 101, 5))\r\n",
        "ax2.set_ylabel('Loss Value')\r\n",
        "ax2.set_xlabel('Epoch')\r\n",
        "ax2.set_title('Loss')\r\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3ksfiza44m4"
      },
      "source": [
        "model.save('1-basic.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rNBHPwm44u8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4h4M9iY441D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A122zR3T444s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oDSCaI44Hp3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF5QOI8r4Hr_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}